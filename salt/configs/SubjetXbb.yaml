name: SubjetXbb

data:
  train_file: /eos/atlas/atlascerngroupdisk/perf-flavtag/training/Xbb/v2/pp_output_train.h5
  val_file: /eos/atlas/atlascerngroupdisk/perf-flavtag/training/Xbb/v2/pp_output_val.h5
  norm_dict: /eos/atlas/atlascerngroupdisk/perf-flavtag/training/Xbb/v2/norm_dict.yaml
  class_dict: /eos/atlas/atlascerngroupdisk/perf-flavtag/training/Xbb/v2/class_dict.yaml
  variables:
    jets:
      - pt
      - eta
      - mass
    tracks:
      - pt
      - eta
      - mass
      - energy
      - deta
      - dphi
      - GN2v00_pb
      - GN2v00_pc
      - GN2v00_pu
  num_train: -1
  num_val: -1
  num_test: -1
  batch_size: 1000
  num_workers: 15

trainer:
  max_epochs: 50
  devices: 1
  callbacks:
    - class_path: salt.callbacks.Checkpoint
      init_args:
        monitor_loss: val/jets_classification_loss
    - class_path: salt.callbacks.PredictionWriter
      init_args:
        jet_variables:
          - pt
          - eta
          - mass
          - R10TruthLabel_R22v1
          - R10TruthLabel_R22v1_TruthJetMass
          - R10TruthLabel_R22v1_TruthJetPt
          - GN2Xv00_phbb
          - GN2Xv00_phcc
          - GN2Xv00_ptop
          - GN2Xv00_pqcd
          - GN2XWithMassv00_phbb
          - GN2XWithMassv00_phcc
          - GN2XWithMassv00_ptop
          - GN2XWithMassv00_pqcd
          - Xbb2020v3_Higgs
          - Xbb2020v3_Top
          - Xbb2020v3_QCD
    - class_path: lightning.pytorch.callbacks.LearningRateMonitor
    - class_path: lightning.pytorch.callbacks.TQDMProgressBar
      init_args:
        refresh_rate: 20
    - class_path: lightning.pytorch.callbacks.ModelSummary
      init_args:
        max_depth: 2

model:
  model:
    class_path: salt.models.SaltModel
    init_args:
      init_nets:
        - input_name: tracks
          dense_config:
            input_size: 12
            output_size: &embed_dim 64
            hidden_layers: [64]
            activation: &activation SiLU

      encoder:
        class_path: salt.models.TransformerEncoder
        init_args:
          embed_dim: *embed_dim
          num_layers: 2
          mha_config:
            num_heads: 2
            attention: { class_path: salt.models.ScaledDotProductAttention }
            out_proj: False
          dense_config:
            activation: *activation
            hidden_layers: [128]
            dropout: &dropout 0.1

      pool_net:
        class_path: salt.models.GlobalAttentionPooling
        init_args: { input_size: *embed_dim }

      tasks:
        class_path: torch.nn.ModuleList
        init_args:
          modules:
            - class_path: salt.models.ClassificationTask
              init_args:
                name: jets_classification
                input_name: jets
                label: flavour_label
                loss: torch.nn.CrossEntropyLoss
                dense_config:
                  input_size: *embed_dim
                  output_size: 4
                  hidden_layers: [64, 32]
                  activation: *activation
                  dropout: *dropout
