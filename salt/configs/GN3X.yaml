name: GN3XPV01
model:
  optimizer: lion
  loss_mode: GLS
  lrs_config:
    initial: 2e-8
    max: 1e-5
    end: 2e-6
    pct_start: 0.01
    weight_decay: 1e-5

  model:
    class_path: salt.models.SaltModel
    init_args:
      init_nets:
        - input_name: tracks
          dense_config:
            output_size: &embed_dim 256
            hidden_layers: [256]
            activation: &activation ReLU
        - input_name: flow
          dense_config:
            output_size: *embed_dim
            hidden_layers: [256]
            activation: *activation

      encoder:
        class_path: salt.models.Transformer
        init_args:
          num_layers: 8
          embed_dim: *embed_dim
          out_dim: &out_dim 128
          attn_type: flash-varlen
          norm: LayerNorm
          dense_kwargs:
            activation: *activation
            dropout: 0.1
            gated: True
          attn_kwargs:
            num_heads: 8
            dropout: 0.1
          num_registers: 8

      pool_net:
        class_path: salt.models.GlobalAttentionPooling
        init_args: { input_size: *out_dim }

      tasks:
        class_path: torch.nn.ModuleList
        init_args:
          modules:
            - class_path: salt.models.ClassificationTask
              init_args:
                name: jets_classification
                input_name: jets
                label: flavour_label
                class_names:
                  [htautauhad, hbb, hcc, top, qcdbb, qcdbx, qcdcx, qcdll, Wqq]
                loss:
                  class_path: torch.nn.CrossEntropyLoss
                  # adjust weight based on flavour fraction in samples
                  # class_dict does not have an entry for new subclasses
                  init_args:
                    {
                      weight: [8.0, 2.0, 2.0, 4.0, 20.0, 20.0, 10.0, 1.5, 16.0],
                    }
                dense_config: &task_dense_config
                  input_size: *out_dim
                  output_size: 9
                  hidden_layers: [128, 64, 32]
                  activation: *activation

            - class_path: salt.models.ClassificationTask
              init_args:
                name: track_origin
                input_name: tracks
                label: ftagTruthOriginLabel
                use_class_dict: True
                loss: torch.nn.CrossEntropyLoss
                dense_config:
                  <<: *task_dense_config
                  output_size: 8
                  context_size: *out_dim
                  activation: *activation

            - class_path: salt.models.VertexingTask
              init_args:
                name: track_vertexing
                input_name: tracks
                label: ftagTruthVertexIndex
                loss:
                  class_path: torch.nn.BCEWithLogitsLoss
                  init_args: { reduction: none }
                dense_config:
                  <<: *task_dense_config
                  input_size: 256
                  output_size: 1
                  context_size: *out_dim
                  activation: *activation

data:
  num_inputs:
    tracks: 100
    flow: 100

  labeller_config:
    use_labeller: True
    class_names: [htautauhad, hbb, hcc, top, qcdbb, qcdbx, qcdcx, qcdll, Wqq]
    require_labels: True

  variables:
    jets:
      - pt
      - eta
      - mass
    tracks:
      - d0
      - z0SinTheta
      - dphi
      - deta
      - qOverP
      - lifetimeSignedD0Significance
      - lifetimeSignedZ0SinThetaSignificance
      - phiUncertainty
      - thetaUncertainty
      - qOverPUncertainty
      - numberOfPixelHits
      - numberOfSCTHits
      - numberOfInnermostPixelLayerHits
      - numberOfNextToInnermostPixelLayerHits
      - numberOfInnermostPixelLayerSharedHits
      - numberOfInnermostPixelLayerSplitHits
      - numberOfPixelSharedHits
      - numberOfPixelSplitHits
      - numberOfSCTSharedHits
      - leptonID
    flow:
      - flow_pt
      - flow_energy
      - flow_deta
      - flow_dphi
  num_train: -1
  num_val: -1
  num_test: -1

  train_file: /share/lustre/ecritelli/xbb_upp_pre_release_Zprimeonly/output/pp_output_train.h5
  val_file: /share/lustre/ecritelli/xbb_upp_pre_release_Zprimeonly/output/pp_output_val.h5
  norm_dict: /share/lustre/ecritelli/xbb_upp_pre_release_Zprimeonly/output/norm_dict.yaml
  class_dict: /share/lustre/ecritelli/xbb_upp_pre_release_Zprimeonly/output/class_dict.yaml

  batch_size: 2500
  num_workers: 10

trainer:
  max_epochs: 25
  accelerator: gpu
  devices: 3
  precision: bf16-mixed
